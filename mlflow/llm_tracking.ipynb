{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LLMOps: LLM Tracking with MLFlow\n",
    "\n",
    "Let's begin with connecting the mlflow server and creating the experiments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5976f3419988a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"llm_tracking\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9522c4afaa2785"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use langchain to talk with chat-gpt3. We have 4 main components:\n",
    "- SystemMessage: The message that is sent to the AI\n",
    "- HumanMessage: The message that is sent to the human\n",
    "- AIMessage: The message that is sent to the AI\n",
    "- ChatOpenAI: The chatbot that we will use to talk with the AI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8869952acb60d66f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:12:31.508852200Z",
     "start_time": "2023-07-29T15:12:31.506339500Z"
    }
   },
   "id": "26130282b770c0fa"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "# Add your OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:12:31.980131500Z",
     "start_time": "2023-07-29T15:12:31.976092800Z"
    }
   },
   "id": "3c5c871ee5e2df6d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:12:32.612533600Z",
     "start_time": "2023-07-29T15:12:32.608534100Z"
    }
   },
   "id": "6691b4c7031ec071"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a human text classifier. You are given a text and you have to classify it as either positive or negative. Given an input text, you will think about the answer first and classify it next. Your output format should be:\n",
    "<Insert what you think>\n",
    "[RESULT]: <1 for positive, 0 for negative, -1 for if you don't know>\n",
    "\"\"\"\n",
    "system_message = SystemMessage(content=system_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:34:06.431724900Z",
     "start_time": "2023-07-29T15:34:06.377587300Z"
    }
   },
   "id": "601def44836de04e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using log_predictions, we can log the inputs and outputs of the model. The inputs are the human messages and the outputs are the AI responses. We can also log the prompts that we used to generate the outputs.\n",
    "This is for offline evaluation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d2d292e5412bf0"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/29 18:34:23 INFO mlflow.tracking.llm_utils: Creating a new llm_predictions.csv for run ddd5253a960e45e997e4851f553e81a1.\n"
     ]
    }
   ],
   "source": [
    "human_messages = []\n",
    "ai_responses = []\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    for i in range(5):\n",
    "        user_input = input(\"Enter your message: \")\n",
    "        human_message = HumanMessage(content=user_input)\n",
    "        human_messages.append(user_input)\n",
    "        ai_message = chat([system_message, human_message])\n",
    "        ai_responses.append(ai_message.content)\n",
    "    \n",
    "    mlflow.llm.log_predictions(inputs=human_messages, outputs=ai_responses,prompts=[system_prompt]*len(human_messages))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:34:23.222861500Z",
     "start_time": "2023-07-29T15:34:06.827822900Z"
    }
   },
   "id": "70e0ff80f24d9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use log_table to log the inputs, outputs and prompts in a table format for comparing the results with other models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22659e711e4be8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "test_dataset = [\n",
    "    \"I love this movie. It's so good!\",\n",
    "    \"I hate this movie. It's so bad!\",\n",
    "    \"I don't know what to think about this movie. It's so-so.\",\n",
    "    \"This product is great. I love it!\",\n",
    "    \"This product is terrible. I hate it!\",\n",
    "]\n",
    "\n",
    "from mlflow.data.pandas_dataset import from_pandas\n",
    "import pandas as pd\n",
    "\n",
    "human_messages = []\n",
    "ai_responses = []\n",
    "with mlflow.start_run(run_name=\"gpt-3.5-turbo-16k\"):\n",
    "    chat = ChatOpenAI(model_name='gpt-3.5-turbo-16k')\n",
    "    test_mlflow_dataset = from_pandas(pd.DataFrame(test_dataset, columns=[\"content\"]))\n",
    "    mlflow.log_input(test_mlflow_dataset, \"test_dataset\")\n",
    "    for i in test_dataset:\n",
    "        human_message = HumanMessage(content=i)\n",
    "        human_messages.append(i)\n",
    "        ai_message = chat([system_message, human_message])\n",
    "        ai_responses.append(ai_message.content)\n",
    "    \n",
    "    mlflow.log_table({\"inputs\":human_messages, \"outputs\":ai_responses, \"prompts\":[system_prompt]*len(human_messages)}, \"predictions\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T15:52:10.858032800Z",
     "start_time": "2023-07-29T15:52:06.999259600Z"
    }
   },
   "id": "332683f8903a8c55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a28bc2b5c03c4d49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
